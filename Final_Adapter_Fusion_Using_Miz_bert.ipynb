{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dETbhPd3Zurz"
      },
      "outputs": [],
      "source": [
        "# Here I Installed necessary libraries\n",
        "!pip install -Uq adapters\n",
        "!pip install -q datasets\n",
        "!pip install -q accelerate\n",
        "!pip install pyarrow==8.0.0\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoC47K1FZ4Ab"
      },
      "outputs": [],
      "source": [
        "# Here I imported required libraries\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from adapters import AutoAdapterModel\n",
        "from transformers import AutoTokenizer, TrainingArguments, EvalPrediction\n",
        "from transformers import TrainingArguments, EarlyStoppingCallback, TrainerCallback\n",
        "from adapters import AdapterTrainer\n",
        "import torch\n",
        "import numpy as np\n",
        "from adapters.composition import Fuse\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcumR_qVZ3_m"
      },
      "outputs": [],
      "source": [
        "# Here I loaded the train and test datasets from Excel files\n",
        "df1 = pd.read_excel(\"/content/Chungli_ao_Train.xlsx\")\n",
        "df2 = pd.read_excel(\"/content/mizo_sentiment_dataset.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x845o0s1Z_zG"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df1, df2])\n",
        "#df = df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ4GX4TLaD2E"
      },
      "outputs": [],
      "source": [
        "trainDf = df\n",
        "testDf = pd.read_excel('/content/Chungli_Ao_test.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbMPozF8aIKH"
      },
      "outputs": [],
      "source": [
        "# Here I drop the __index_level_0__ column if it exists\n",
        "if '__index_level_0__' in trainDf.columns:\n",
        "    trainDf.drop(columns=['__index_level_0__'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_EJsT_TaLh4"
      },
      "outputs": [],
      "source": [
        "# Here I mapped the sentiment labels to integers\n",
        "labelMapping = {\"POSITIVE\": 1, \"NEGATIVE\": 0}\n",
        "trainDf[\"Sentiment\"] = trainDf[\"Sentiment\"].map(labelMapping)\n",
        "testDf[\"Sentiment\"] = testDf[\"Sentiment\"].map(labelMapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNcXFp1oaOAh"
      },
      "outputs": [],
      "source": [
        "# Here I split the training data into 80% train and 20% validation sets\n",
        "trainDf, valDf = train_test_split(trainDf, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6FXMGBlaQN_"
      },
      "outputs": [],
      "source": [
        "# Here, I converted the dataframes to datasets\n",
        "trainDataset = Dataset.from_pandas(trainDf)\n",
        "valDataset = Dataset.from_pandas(valDf)\n",
        "testDataset = Dataset.from_pandas(testDf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZcxK0j_aStm"
      },
      "outputs": [],
      "source": [
        "# Here, I loaded Mizo BERT tokenizer and model instead of Chungli Ao BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"robzchhangte/MizBERT\")\n",
        "model = AutoAdapterModel.from_pretrained(\"robzchhangte/MizBERT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzH79CsIaWD7"
      },
      "outputs": [],
      "source": [
        "# Here I loaded the Mizo adapter and Chungli Ao adapter\n",
        "model.load_adapter(\"tona3738/my-chungliao-adapter\", load_as=\"myChungliaoAdapter\", set_active=True)\n",
        "model.load_adapter(\"tona3738/my-mizo-adapter\", load_as=\"myMizoAdapter\", set_active=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjKd7IE1aY-o"
      },
      "outputs": [],
      "source": [
        "# Here, I did Adapter Fusion setup\n",
        "adapterSetup = Fuse(\"myChungliaoAdapter\", \"myMizoAdapter\")\n",
        "model.add_adapter_fusion(adapterSetup)\n",
        "model.train_adapter(adapterSetup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5V903ZzadMs"
      },
      "outputs": [],
      "source": [
        "# Here, I added classification head for the target task (binary sentiment classification)\n",
        "numLabels = 2\n",
        "model.add_classification_head(\n",
        "    \"mizoSentimentTask\",\n",
        "    num_labels=numLabels,\n",
        "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        ")\n",
        "\n",
        "# Here, I duilt a function to encode datasets\n",
        "def encodeBatch(batch):\n",
        "    encoding = tokenizer(\n",
        "        batch[\"Text\"],\n",
        "        max_length=180,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    encoding[\"labels\"] = batch[\"Sentiment\"]\n",
        "    return encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy9H_EXVafzu"
      },
      "outputs": [],
      "source": [
        "# Here, I encoded datasets\n",
        "trainDataset = trainDataset.map(encodeBatch, batched=True)\n",
        "valDataset = valDataset.map(encodeBatch, batched=True)\n",
        "testDataset = testDataset.map(encodeBatch, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0W_GVnbaljL"
      },
      "outputs": [],
      "source": [
        "# Here, I Set the format for PyTorch\n",
        "trainDataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "valDataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "testDataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcHRVNKga31N"
      },
      "outputs": [],
      "source": [
        "# Here, I Define metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'Accuracy': acc, 'F1': f1, 'Precision': precision, 'Recall': recall}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a2ra0CxYrU8"
      },
      "outputs": [],
      "source": [
        "# Here, I Set up training arguments\n",
        "trainingArgs = TrainingArguments(\n",
        "    learning_rate=0.0001,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"./training_output\",\n",
        "    logging_dir='./logs',\n",
        "    overwrite_output_dir=True,\n",
        "    remove_unused_columns=False,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    load_best_model_at_end=True,  # Load the best model\n",
        "    report_to='wandb',\n",
        "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.001,\n",
        ")\n",
        "\n",
        "# Here, I initialized the trainer with the training arguments\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=trainingArgs,\n",
        "    train_dataset=trainDataset,\n",
        "    eval_dataset=valDataset,  # Here I used the validation dataset for evaluation during training\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
        ")\n",
        "\n",
        "# Here, I trained the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYfZYpSDY1sT"
      },
      "outputs": [],
      "source": [
        "# Here, I evaluated the model on validation set\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSuE9dVmY5RE"
      },
      "outputs": [],
      "source": [
        "# Here, I evaluated the model on the test dataset\n",
        "testEvalResult = trainer.evaluate(eval_dataset=testDataset)\n",
        "print(testEvalResult)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
